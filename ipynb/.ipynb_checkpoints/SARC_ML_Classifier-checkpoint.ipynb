{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we classify sarcastic and nonsarcastic comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create function to read in a random sample of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p is set to a value between 0.0 and 1.0, so we can read in a percentage `p` sized portion of the data\n",
    "p = 1.0\n",
    "\n",
    "def read_in_data(file):\n",
    "    return pd.read_csv(file, \n",
    "                       sep='\\t', \n",
    "                       header=None, \n",
    "                       names=['label','comment','author','subreddit','score',\n",
    "                              'ups','downs','date','created_utc','parent_comment'],\n",
    "                       usecols=['label','comment','author','subreddit','score',\n",
    "                              'date','created_utc','parent_comment'],  \n",
    "                       skiprows=lambda i: i>0 and random.random() > p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in a random sample of the data from **data_train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>1476662123</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4</td>\n",
       "      <td>2016-11</td>\n",
       "      <td>1477959850</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>1474580737</td>\n",
       "      <td>They're favored to win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>icebrotha</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>-8</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>1476824627</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>cush2push</td>\n",
       "      <td>MaddenUltimateTeam</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-12</td>\n",
       "      <td>1483117213</td>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment     author  \\\n",
       "0      0                                         NC and NH.  Trumpbart   \n",
       "1      0  You do know west teams play against west teams...  Shbshb906   \n",
       "2      0  They were underdogs earlier today, but since G...   Creepeth   \n",
       "3      0  This meme isn't funny none of the \"new york ni...  icebrotha   \n",
       "4      0                    I could use one of those tools.  cush2push   \n",
       "\n",
       "            subreddit  score     date  created_utc  \\\n",
       "0            politics      2  2016-10   1476662123   \n",
       "1                 nba     -4  2016-11   1477959850   \n",
       "2                 nfl      3  2016-09   1474580737   \n",
       "3  BlackPeopleTwitter     -8  2016-10   1476824627   \n",
       "4  MaddenUltimateTeam      6  2016-12   1483117213   \n",
       "\n",
       "                                      parent_comment  \n",
       "0  Yeah, I get that argument. At this point, I'd ...  \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...  \n",
       "2                            They're favored to win.  \n",
       "3                         deadass don't kill my buzz  \n",
       "4  Yep can confirm I saw the tool they use for th...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = read_in_data(\"../data/train-balanced.csv\")\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create function to reorder cols for easy comparison of comments as they are transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_col_headers(df, cols):\n",
    "    return df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run reorder_col_headers on **data_train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3</td>\n",
       "      <td>They're favored to win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>icebrotha</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>-8</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>cush2push</td>\n",
       "      <td>MaddenUltimateTeam</td>\n",
       "      <td>6</td>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment     author  \\\n",
       "0      0                                         NC and NH.  Trumpbart   \n",
       "1      0  You do know west teams play against west teams...  Shbshb906   \n",
       "2      0  They were underdogs earlier today, but since G...   Creepeth   \n",
       "3      0  This meme isn't funny none of the \"new york ni...  icebrotha   \n",
       "4      0                    I could use one of those tools.  cush2push   \n",
       "\n",
       "            subreddit  score  \\\n",
       "0            politics      2   \n",
       "1                 nba     -4   \n",
       "2                 nfl      3   \n",
       "3  BlackPeopleTwitter     -8   \n",
       "4  MaddenUltimateTeam      6   \n",
       "\n",
       "                                      parent_comment  \n",
       "0  Yeah, I get that argument. At this point, I'd ...  \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...  \n",
       "2                            They're favored to win.  \n",
       "3                         deadass don't kill my buzz  \n",
       "4  Yep can confirm I saw the tool they use for th...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = reorder_col_headers(data_train, \n",
    "                                 ['label', 'comment', 'author', 'subreddit', 'score', 'parent_comment'])\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create function to find NA values, if any, in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_NA_values_in_data(df):\n",
    "    # Any NAs?\n",
    "    print('NAs exist in this sample (T/F):', df.isnull().values.any(), '\\n')\n",
    "    # How many?\n",
    "    print('How many NAs in this sample?', df.isnull().sum().sum(), '\\n')\n",
    "    # In which columns?\n",
    "    print('Which cols have NAs in this sample?\\n')\n",
    "    print(df.isnull().any(), '\\n')\n",
    "\n",
    "    # How many of them are sarcasm?\n",
    "    print('Of these NAs, how many are labeled sarcasm?\\n')\n",
    "    nulls = df[df['comment'].isnull()]  \n",
    "    print('\\tNumber of null comments in sample:', len(nulls))\n",
    "    nulls_sarc = nulls[nulls['label'] == 1]\n",
    "    print('\\tNumber of null comments in sample that are sarcasm:',len(nulls_sarc))\n",
    "    if not len(nulls) == 0:\n",
    "        print('\\tRatio of sarcastic null comments to all null comments in sample:', len(nulls_sarc) / len(nulls))\n",
    "    else:\n",
    "        print('\\tRatio of sarcastic null comments to all null comments in sample: 0 of 0')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run identify_NA_values_in_data on **data_train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify_NA_values_in_data(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in a random sample of the data from **data_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251608, 6) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Actually most of her supporters and sane peopl...</td>\n",
       "      <td>Quinnjester</td>\n",
       "      <td>politics</td>\n",
       "      <td>3</td>\n",
       "      <td>Hillary's Surrogotes Told to Blame Media for '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>They can't survive without an echo chamber whi...</td>\n",
       "      <td>TheGettysburgAddress</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>13</td>\n",
       "      <td>Thank God Liberals like to live in concentrate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>you're pretty cute yourself 1729 total</td>\n",
       "      <td>Sempiternally_free</td>\n",
       "      <td>2007scape</td>\n",
       "      <td>8</td>\n",
       "      <td>Saw this cutie training his Attack today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>If you kill me you'll crash the meme market</td>\n",
       "      <td>Catacomb82</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>2</td>\n",
       "      <td>If you were locked in a room with 49 other peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I bet he wrote that last message as he was sob...</td>\n",
       "      <td>Dorian-throwaway</td>\n",
       "      <td>niceguys</td>\n",
       "      <td>5</td>\n",
       "      <td>You're not even that pretty!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment  \\\n",
       "0      0  Actually most of her supporters and sane peopl...   \n",
       "1      0  They can't survive without an echo chamber whi...   \n",
       "2      0             you're pretty cute yourself 1729 total   \n",
       "3      0        If you kill me you'll crash the meme market   \n",
       "4      0  I bet he wrote that last message as he was sob...   \n",
       "\n",
       "                 author   subreddit  score  \\\n",
       "0           Quinnjester    politics      3   \n",
       "1  TheGettysburgAddress  The_Donald     13   \n",
       "2    Sempiternally_free   2007scape      8   \n",
       "3            Catacomb82   AskReddit      2   \n",
       "4      Dorian-throwaway    niceguys      5   \n",
       "\n",
       "                                      parent_comment  \n",
       "0  Hillary's Surrogotes Told to Blame Media for '...  \n",
       "1  Thank God Liberals like to live in concentrate...  \n",
       "2        Saw this cutie training his Attack today...  \n",
       "3  If you were locked in a room with 49 other peo...  \n",
       "4                       You're not even that pretty!  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = read_in_data(\"../data/test-balanced.csv\")\n",
    "data_test = reorder_col_headers(data_test, \n",
    "                                 ['label', 'comment', 'author', 'subreddit', 'score', 'parent_comment'])\n",
    "\n",
    "print(data_test.shape, '\\n')\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create function to inspect data types and memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_df_info(df):\n",
    "    return df.info(memory_usage='deep', null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run view_df_info on **data_train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1010826 entries, 0 to 1010825\n",
      "Data columns (total 6 columns):\n",
      "label             1010826 non-null int64\n",
      "comment           1010773 non-null object\n",
      "author            1010826 non-null object\n",
      "subreddit         1010826 non-null object\n",
      "score             1010826 non-null int64\n",
      "parent_comment    1010826 non-null object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 437.7 MB\n"
     ]
    }
   ],
   "source": [
    "view_df_info(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `view_df_info` on **data_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 251608 entries, 0 to 251607\n",
      "Data columns (total 6 columns):\n",
      "label             251608 non-null int64\n",
      "comment           251594 non-null object\n",
      "author            251608 non-null object\n",
      "subreddit         251608 non-null object\n",
      "score             251608 non-null int64\n",
      "parent_comment    251608 non-null object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 108.9 MB\n"
     ]
    }
   ],
   "source": [
    "view_df_info(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `describe()` on **data_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_train\n",
      "                label          score\n",
      "count  251608.000000  251608.000000\n",
      "mean        0.500000       6.757452\n",
      "std         0.500001      48.450781\n",
      "min         0.000000    -329.000000\n",
      "25%         0.000000       1.000000\n",
      "50%         0.500000       2.000000\n",
      "75%         1.000000       4.000000\n",
      "max         1.000000    9923.000000\n"
     ]
    }
   ],
   "source": [
    "print('data_train\\n', data_test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run identify_NA_values_in_data on **data_train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAs exist in this sample (T/F): True \n",
      "\n",
      "How many NAs in this sample? 53 \n",
      "\n",
      "Which cols have NAs in this sample?\n",
      "\n",
      "label             False\n",
      "comment            True\n",
      "author            False\n",
      "subreddit         False\n",
      "score             False\n",
      "parent_comment    False\n",
      "dtype: bool \n",
      "\n",
      "Of these NAs, how many are labeled sarcasm?\n",
      "\n",
      "\tNumber of null comments in sample: 53\n",
      "\tNumber of null comments in sample that are sarcasm: 45\n",
      "\tRatio of sarcastic null comments to all null comments in sample: 0.8490566037735849\n"
     ]
    }
   ],
   "source": [
    "identify_NA_values_in_data(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run identify_NA_values_in_data on **data_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAs exist in this sample (T/F): True \n",
      "\n",
      "How many NAs in this sample? 14 \n",
      "\n",
      "Which cols have NAs in this sample?\n",
      "\n",
      "label             False\n",
      "comment            True\n",
      "author            False\n",
      "subreddit         False\n",
      "score             False\n",
      "parent_comment    False\n",
      "dtype: bool \n",
      "\n",
      "Of these NAs, how many are labeled sarcasm?\n",
      "\n",
      "\tNumber of null comments in sample: 14\n",
      "\tNumber of null comments in sample that are sarcasm: 9\n",
      "\tRatio of sarcastic null comments to all null comments in sample: 0.6428571428571429\n"
     ]
    }
   ],
   "source": [
    "identify_NA_values_in_data(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.dropna(inplace=True)\n",
    "data_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create function to remove punctuation from corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(comment):\n",
    "    '''This function uses str methods from the string class to remove punctuation from the text.'''\n",
    "    \n",
    "    # replace punctuation with '' (no space)\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    \n",
    "    # return the text stripped of punctuation marks\n",
    "    return comment.translate(translator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run function `` on **data_train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_train\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today but since Gr...</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3</td>\n",
       "      <td>They're favored to win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isnt funny none of the new york nigg...</td>\n",
       "      <td>icebrotha</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>-8</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools</td>\n",
       "      <td>cush2push</td>\n",
       "      <td>MaddenUltimateTeam</td>\n",
       "      <td>6</td>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment     author  \\\n",
       "0      0                                          NC and NH  Trumpbart   \n",
       "1      0  You do know west teams play against west teams...  Shbshb906   \n",
       "2      0  They were underdogs earlier today but since Gr...   Creepeth   \n",
       "3      0  This meme isnt funny none of the new york nigg...  icebrotha   \n",
       "4      0                     I could use one of those tools  cush2push   \n",
       "\n",
       "            subreddit  score  \\\n",
       "0            politics      2   \n",
       "1                 nba     -4   \n",
       "2                 nfl      3   \n",
       "3  BlackPeopleTwitter     -8   \n",
       "4  MaddenUltimateTeam      6   \n",
       "\n",
       "                                      parent_comment  \n",
       "0  Yeah, I get that argument. At this point, I'd ...  \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...  \n",
       "2                            They're favored to win.  \n",
       "3                         deadass don't kill my buzz  \n",
       "4  Yep can confirm I saw the tool they use for th...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['comment'] = data_train['comment'].apply(remove_punc)\n",
    "\n",
    "print('data_train\\n')\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run function `` on **data_train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_test\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Actually most of her supporters and sane peopl...</td>\n",
       "      <td>Quinnjester</td>\n",
       "      <td>politics</td>\n",
       "      <td>3</td>\n",
       "      <td>Hillary's Surrogotes Told to Blame Media for '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>They cant survive without an echo chamber whic...</td>\n",
       "      <td>TheGettysburgAddress</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>13</td>\n",
       "      <td>Thank God Liberals like to live in concentrate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>youre pretty cute yourself 1729 total</td>\n",
       "      <td>Sempiternally_free</td>\n",
       "      <td>2007scape</td>\n",
       "      <td>8</td>\n",
       "      <td>Saw this cutie training his Attack today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>If you kill me youll crash the meme market</td>\n",
       "      <td>Catacomb82</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>2</td>\n",
       "      <td>If you were locked in a room with 49 other peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I bet he wrote that last message as he was sob...</td>\n",
       "      <td>Dorian-throwaway</td>\n",
       "      <td>niceguys</td>\n",
       "      <td>5</td>\n",
       "      <td>You're not even that pretty!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment  \\\n",
       "0      0  Actually most of her supporters and sane peopl...   \n",
       "1      0  They cant survive without an echo chamber whic...   \n",
       "2      0              youre pretty cute yourself 1729 total   \n",
       "3      0         If you kill me youll crash the meme market   \n",
       "4      0  I bet he wrote that last message as he was sob...   \n",
       "\n",
       "                 author   subreddit  score  \\\n",
       "0           Quinnjester    politics      3   \n",
       "1  TheGettysburgAddress  The_Donald     13   \n",
       "2    Sempiternally_free   2007scape      8   \n",
       "3            Catacomb82   AskReddit      2   \n",
       "4      Dorian-throwaway    niceguys      5   \n",
       "\n",
       "                                      parent_comment  \n",
       "0  Hillary's Surrogotes Told to Blame Media for '...  \n",
       "1  Thank God Liberals like to live in concentrate...  \n",
       "2        Saw this cutie training his Attack today...  \n",
       "3  If you were locked in a room with 49 other peo...  \n",
       "4                       You're not even that pretty!  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['comment'] = data_test['comment'].apply(remove_punc)\n",
    "\n",
    "print('data_test\\n')\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with stopwords and letter casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you',\n",
       "       \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself',\n",
       "       'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her',\n",
       "       'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them',\n",
       "       'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom',\n",
       "       'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are',\n",
       "       'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had',\n",
       "       'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and',\n",
       "       'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at',\n",
       "       'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
       "       'through', 'during', 'before', 'after', 'above', 'below', 'to',\n",
       "       'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under',\n",
       "       'again', 'further', 'then', 'once', 'here', 'there', 'when',\n",
       "       'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
       "       'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own',\n",
       "       'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will',\n",
       "       'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll',\n",
       "       'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn',\n",
       "       \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\",\n",
       "       'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma',\n",
       "       'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\",\n",
       "       'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\",\n",
       "       'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load stopwords from NLTK\n",
    "sw = stopwords.words('english')\n",
    "# view stop words\n",
    "np.array(sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create function to ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_and_lowercase(comment):\n",
    "    '''This function lowercases words and then remove stopwords.'''\n",
    "    \n",
    "    comment = \\\n",
    "    [word.lower() for word in comment.split() if word.lower() not in sw]\n",
    "    return ' '.join(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run function `` on **data_train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_lc_stopped</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH</td>\n",
       "      <td>nc nh</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>know west teams play west teams east teams right</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today but since Gr...</td>\n",
       "      <td>underdogs earlier today since gronks announcem...</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3</td>\n",
       "      <td>They're favored to win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isnt funny none of the new york nigg...</td>\n",
       "      <td>meme isnt funny none new york nigga ones</td>\n",
       "      <td>icebrotha</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>-8</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools</td>\n",
       "      <td>could use one tools</td>\n",
       "      <td>cush2push</td>\n",
       "      <td>MaddenUltimateTeam</td>\n",
       "      <td>6</td>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment  \\\n",
       "0      0                                          NC and NH   \n",
       "1      0  You do know west teams play against west teams...   \n",
       "2      0  They were underdogs earlier today but since Gr...   \n",
       "3      0  This meme isnt funny none of the new york nigg...   \n",
       "4      0                     I could use one of those tools   \n",
       "\n",
       "                                  comment_lc_stopped     author  \\\n",
       "0                                              nc nh  Trumpbart   \n",
       "1   know west teams play west teams east teams right  Shbshb906   \n",
       "2  underdogs earlier today since gronks announcem...   Creepeth   \n",
       "3           meme isnt funny none new york nigga ones  icebrotha   \n",
       "4                                could use one tools  cush2push   \n",
       "\n",
       "            subreddit  score  \\\n",
       "0            politics      2   \n",
       "1                 nba     -4   \n",
       "2                 nfl      3   \n",
       "3  BlackPeopleTwitter     -8   \n",
       "4  MaddenUltimateTeam      6   \n",
       "\n",
       "                                      parent_comment  \n",
       "0  Yeah, I get that argument. At this point, I'd ...  \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...  \n",
       "2                            They're favored to win.  \n",
       "3                         deadass don't kill my buzz  \n",
       "4  Yep can confirm I saw the tool they use for th...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to each comment\n",
    "data_train['comment_lc_stopped'] = data_train['comment'].apply(remove_stopwords_and_lowercase)\n",
    "data_train = reorder_col_headers(data_train, \n",
    "                                 ['label', 'comment', 'comment_lc_stopped', 'author', \n",
    "                                  'subreddit', 'score', 'parent_comment'])\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run function `` on **data_train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_lc_stopped</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Actually most of her supporters and sane peopl...</td>\n",
       "      <td>actually supporters sane people saw media doin...</td>\n",
       "      <td>Quinnjester</td>\n",
       "      <td>politics</td>\n",
       "      <td>3</td>\n",
       "      <td>Hillary's Surrogotes Told to Blame Media for '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>They cant survive without an echo chamber whic...</td>\n",
       "      <td>cant survive without echo chamber great america</td>\n",
       "      <td>TheGettysburgAddress</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>13</td>\n",
       "      <td>Thank God Liberals like to live in concentrate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>youre pretty cute yourself 1729 total</td>\n",
       "      <td>youre pretty cute 1729 total</td>\n",
       "      <td>Sempiternally_free</td>\n",
       "      <td>2007scape</td>\n",
       "      <td>8</td>\n",
       "      <td>Saw this cutie training his Attack today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>If you kill me youll crash the meme market</td>\n",
       "      <td>kill youll crash meme market</td>\n",
       "      <td>Catacomb82</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>2</td>\n",
       "      <td>If you were locked in a room with 49 other peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I bet he wrote that last message as he was sob...</td>\n",
       "      <td>bet wrote last message sobbing</td>\n",
       "      <td>Dorian-throwaway</td>\n",
       "      <td>niceguys</td>\n",
       "      <td>5</td>\n",
       "      <td>You're not even that pretty!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment  \\\n",
       "0      0  Actually most of her supporters and sane peopl...   \n",
       "1      0  They cant survive without an echo chamber whic...   \n",
       "2      0              youre pretty cute yourself 1729 total   \n",
       "3      0         If you kill me youll crash the meme market   \n",
       "4      0  I bet he wrote that last message as he was sob...   \n",
       "\n",
       "                                  comment_lc_stopped                author  \\\n",
       "0  actually supporters sane people saw media doin...           Quinnjester   \n",
       "1    cant survive without echo chamber great america  TheGettysburgAddress   \n",
       "2                       youre pretty cute 1729 total    Sempiternally_free   \n",
       "3                       kill youll crash meme market            Catacomb82   \n",
       "4                     bet wrote last message sobbing      Dorian-throwaway   \n",
       "\n",
       "    subreddit  score                                     parent_comment  \n",
       "0    politics      3  Hillary's Surrogotes Told to Blame Media for '...  \n",
       "1  The_Donald     13  Thank God Liberals like to live in concentrate...  \n",
       "2   2007scape      8        Saw this cutie training his Attack today...  \n",
       "3   AskReddit      2  If you were locked in a room with 49 other peo...  \n",
       "4    niceguys      5                       You're not even that pretty!  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['comment_lc_stopped'] = data_test['comment'].apply(remove_stopwords_and_lowercase)\n",
    "data_test = reorder_col_headers(data_test, \n",
    "                                 ['label', 'comment', 'comment_lc_stopped', 'author', \n",
    "                                  'subreddit', 'score', 'parent_comment'])\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stem all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create function to ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_each_word(text):\n",
    "    '''This function stems each word in `text`'''\n",
    "    \n",
    "    text = [stemmer.stem(word) for word in text.split()]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run function `` on **data_train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_lc_stopped</th>\n",
       "      <th>comment_stemmed</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH</td>\n",
       "      <td>nc nh</td>\n",
       "      <td>nc nh</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>know west teams play west teams east teams right</td>\n",
       "      <td>know west team play west team east team right</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today but since Gr...</td>\n",
       "      <td>underdogs earlier today since gronks announcem...</td>\n",
       "      <td>underdog earlier today sinc gronk announc afte...</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3</td>\n",
       "      <td>They're favored to win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isnt funny none of the new york nigg...</td>\n",
       "      <td>meme isnt funny none new york nigga ones</td>\n",
       "      <td>meme isnt funni none new york nigga one</td>\n",
       "      <td>icebrotha</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>-8</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools</td>\n",
       "      <td>could use one tools</td>\n",
       "      <td>could use one tool</td>\n",
       "      <td>cush2push</td>\n",
       "      <td>MaddenUltimateTeam</td>\n",
       "      <td>6</td>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment  \\\n",
       "0      0                                          NC and NH   \n",
       "1      0  You do know west teams play against west teams...   \n",
       "2      0  They were underdogs earlier today but since Gr...   \n",
       "3      0  This meme isnt funny none of the new york nigg...   \n",
       "4      0                     I could use one of those tools   \n",
       "\n",
       "                                  comment_lc_stopped  \\\n",
       "0                                              nc nh   \n",
       "1   know west teams play west teams east teams right   \n",
       "2  underdogs earlier today since gronks announcem...   \n",
       "3           meme isnt funny none new york nigga ones   \n",
       "4                                could use one tools   \n",
       "\n",
       "                                     comment_stemmed     author  \\\n",
       "0                                              nc nh  Trumpbart   \n",
       "1      know west team play west team east team right  Shbshb906   \n",
       "2  underdog earlier today sinc gronk announc afte...   Creepeth   \n",
       "3            meme isnt funni none new york nigga one  icebrotha   \n",
       "4                                 could use one tool  cush2push   \n",
       "\n",
       "            subreddit  score  \\\n",
       "0            politics      2   \n",
       "1                 nba     -4   \n",
       "2                 nfl      3   \n",
       "3  BlackPeopleTwitter     -8   \n",
       "4  MaddenUltimateTeam      6   \n",
       "\n",
       "                                      parent_comment  \n",
       "0  Yeah, I get that argument. At this point, I'd ...  \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...  \n",
       "2                            They're favored to win.  \n",
       "3                         deadass don't kill my buzz  \n",
       "4  Yep can confirm I saw the tool they use for th...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply stem_each_word function to each TRAIN and TEST comment\n",
    "\n",
    "# TRAIN\n",
    "data_train['comment_stemmed'] = data_train['comment_lc_stopped'].apply(stem_each_word)\n",
    "data_train = reorder_col_headers(data_train, \n",
    "                                 ['label', 'comment', 'comment_lc_stopped', 'comment_stemmed', 'author', \n",
    "                                  'subreddit', 'score', 'parent_comment'])\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run function `` on **data_train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_lc_stopped</th>\n",
       "      <th>comment_stemmed</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Actually most of her supporters and sane peopl...</td>\n",
       "      <td>actually supporters sane people saw media doin...</td>\n",
       "      <td>actual support sane peopl saw media doingespec...</td>\n",
       "      <td>Quinnjester</td>\n",
       "      <td>politics</td>\n",
       "      <td>3</td>\n",
       "      <td>Hillary's Surrogotes Told to Blame Media for '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>They cant survive without an echo chamber whic...</td>\n",
       "      <td>cant survive without echo chamber great america</td>\n",
       "      <td>cant surviv without echo chamber great america</td>\n",
       "      <td>TheGettysburgAddress</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>13</td>\n",
       "      <td>Thank God Liberals like to live in concentrate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>youre pretty cute yourself 1729 total</td>\n",
       "      <td>youre pretty cute 1729 total</td>\n",
       "      <td>your pretti cute 1729 total</td>\n",
       "      <td>Sempiternally_free</td>\n",
       "      <td>2007scape</td>\n",
       "      <td>8</td>\n",
       "      <td>Saw this cutie training his Attack today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>If you kill me youll crash the meme market</td>\n",
       "      <td>kill youll crash meme market</td>\n",
       "      <td>kill youll crash meme market</td>\n",
       "      <td>Catacomb82</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>2</td>\n",
       "      <td>If you were locked in a room with 49 other peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I bet he wrote that last message as he was sob...</td>\n",
       "      <td>bet wrote last message sobbing</td>\n",
       "      <td>bet wrote last messag sob</td>\n",
       "      <td>Dorian-throwaway</td>\n",
       "      <td>niceguys</td>\n",
       "      <td>5</td>\n",
       "      <td>You're not even that pretty!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment  \\\n",
       "0      0  Actually most of her supporters and sane peopl...   \n",
       "1      0  They cant survive without an echo chamber whic...   \n",
       "2      0              youre pretty cute yourself 1729 total   \n",
       "3      0         If you kill me youll crash the meme market   \n",
       "4      0  I bet he wrote that last message as he was sob...   \n",
       "\n",
       "                                  comment_lc_stopped  \\\n",
       "0  actually supporters sane people saw media doin...   \n",
       "1    cant survive without echo chamber great america   \n",
       "2                       youre pretty cute 1729 total   \n",
       "3                       kill youll crash meme market   \n",
       "4                     bet wrote last message sobbing   \n",
       "\n",
       "                                     comment_stemmed                author  \\\n",
       "0  actual support sane peopl saw media doingespec...           Quinnjester   \n",
       "1     cant surviv without echo chamber great america  TheGettysburgAddress   \n",
       "2                        your pretti cute 1729 total    Sempiternally_free   \n",
       "3                       kill youll crash meme market            Catacomb82   \n",
       "4                          bet wrote last messag sob      Dorian-throwaway   \n",
       "\n",
       "    subreddit  score                                     parent_comment  \n",
       "0    politics      3  Hillary's Surrogotes Told to Blame Media for '...  \n",
       "1  The_Donald     13  Thank God Liberals like to live in concentrate...  \n",
       "2   2007scape      8        Saw this cutie training his Attack today...  \n",
       "3   AskReddit      2  If you were locked in a room with 49 other peo...  \n",
       "4    niceguys      5                       You're not even that pretty!  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "data_test['comment_stemmed'] = data_test['comment_lc_stopped'].apply(stem_each_word)\n",
    "data_test = reorder_col_headers(data_test, \n",
    "                                 ['label', 'comment', 'comment_lc_stopped', 'comment_stemmed', 'author', \n",
    "                                  'subreddit', 'score', 'parent_comment'])\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use nltk.stem WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create function to ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_each_word(text):\n",
    "    '''This function lemmatizes each word, e.g., \n",
    "    - Remove the final \"s\" or \"es\" to singularize plurals and change person of some verbs\n",
    "      (gets --> get,\n",
    "      passes --> pass, \n",
    "      BUT not always as expected: \n",
    "      does --> doe (a deer, a female deer), \n",
    "      capitalizes --> captializes)\n",
    "    '''\n",
    "    text = [lemmatizer.lemmatize(word) for word in text.split()]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run function `` on **data_train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_lc_stopped</th>\n",
       "      <th>comment_stemmed</th>\n",
       "      <th>comment_stemmed_lemmed</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH</td>\n",
       "      <td>nc nh</td>\n",
       "      <td>nc nh</td>\n",
       "      <td>nc nh</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>know west teams play west teams east teams right</td>\n",
       "      <td>know west team play west team east team right</td>\n",
       "      <td>know west team play west team east team right</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today but since Gr...</td>\n",
       "      <td>underdogs earlier today since gronks announcem...</td>\n",
       "      <td>underdog earlier today sinc gronk announc afte...</td>\n",
       "      <td>underdog earlier today sinc gronk announc afte...</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3</td>\n",
       "      <td>They're favored to win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isnt funny none of the new york nigg...</td>\n",
       "      <td>meme isnt funny none new york nigga ones</td>\n",
       "      <td>meme isnt funni none new york nigga one</td>\n",
       "      <td>meme isnt funni none new york nigga one</td>\n",
       "      <td>icebrotha</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>-8</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools</td>\n",
       "      <td>could use one tools</td>\n",
       "      <td>could use one tool</td>\n",
       "      <td>could use one tool</td>\n",
       "      <td>cush2push</td>\n",
       "      <td>MaddenUltimateTeam</td>\n",
       "      <td>6</td>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment  \\\n",
       "0      0                                          NC and NH   \n",
       "1      0  You do know west teams play against west teams...   \n",
       "2      0  They were underdogs earlier today but since Gr...   \n",
       "3      0  This meme isnt funny none of the new york nigg...   \n",
       "4      0                     I could use one of those tools   \n",
       "\n",
       "                                  comment_lc_stopped  \\\n",
       "0                                              nc nh   \n",
       "1   know west teams play west teams east teams right   \n",
       "2  underdogs earlier today since gronks announcem...   \n",
       "3           meme isnt funny none new york nigga ones   \n",
       "4                                could use one tools   \n",
       "\n",
       "                                     comment_stemmed  \\\n",
       "0                                              nc nh   \n",
       "1      know west team play west team east team right   \n",
       "2  underdog earlier today sinc gronk announc afte...   \n",
       "3            meme isnt funni none new york nigga one   \n",
       "4                                 could use one tool   \n",
       "\n",
       "                              comment_stemmed_lemmed     author  \\\n",
       "0                                              nc nh  Trumpbart   \n",
       "1      know west team play west team east team right  Shbshb906   \n",
       "2  underdog earlier today sinc gronk announc afte...   Creepeth   \n",
       "3            meme isnt funni none new york nigga one  icebrotha   \n",
       "4                                 could use one tool  cush2push   \n",
       "\n",
       "            subreddit  score  \\\n",
       "0            politics      2   \n",
       "1                 nba     -4   \n",
       "2                 nfl      3   \n",
       "3  BlackPeopleTwitter     -8   \n",
       "4  MaddenUltimateTeam      6   \n",
       "\n",
       "                                      parent_comment  \n",
       "0  Yeah, I get that argument. At this point, I'd ...  \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...  \n",
       "2                            They're favored to win.  \n",
       "3                         deadass don't kill my buzz  \n",
       "4  Yep can confirm I saw the tool they use for th...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply lemmatize_each_word(text) function to each TRAIN and TEST comment\n",
    "\n",
    "# TRAIN\n",
    "data_train['comment_stemmed_lemmed'] = data_train['comment_stemmed'].apply(lemmatize_each_word)\n",
    "data_train = reorder_col_headers(data_train, \n",
    "                                 ['label', 'comment', 'comment_lc_stopped', 'comment_stemmed', 'comment_stemmed_lemmed',\n",
    "                                  'author', 'subreddit', 'score', 'parent_comment'])\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run function `` on **data_train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_lc_stopped</th>\n",
       "      <th>comment_stemmed</th>\n",
       "      <th>comment_stemmed_lemmed</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Actually most of her supporters and sane peopl...</td>\n",
       "      <td>actually supporters sane people saw media doin...</td>\n",
       "      <td>actual support sane peopl saw media doingespec...</td>\n",
       "      <td>actual support sane peopl saw medium doingespe...</td>\n",
       "      <td>Quinnjester</td>\n",
       "      <td>politics</td>\n",
       "      <td>3</td>\n",
       "      <td>Hillary's Surrogotes Told to Blame Media for '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>They cant survive without an echo chamber whic...</td>\n",
       "      <td>cant survive without echo chamber great america</td>\n",
       "      <td>cant surviv without echo chamber great america</td>\n",
       "      <td>cant surviv without echo chamber great america</td>\n",
       "      <td>TheGettysburgAddress</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>13</td>\n",
       "      <td>Thank God Liberals like to live in concentrate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>youre pretty cute yourself 1729 total</td>\n",
       "      <td>youre pretty cute 1729 total</td>\n",
       "      <td>your pretti cute 1729 total</td>\n",
       "      <td>your pretti cute 1729 total</td>\n",
       "      <td>Sempiternally_free</td>\n",
       "      <td>2007scape</td>\n",
       "      <td>8</td>\n",
       "      <td>Saw this cutie training his Attack today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>If you kill me youll crash the meme market</td>\n",
       "      <td>kill youll crash meme market</td>\n",
       "      <td>kill youll crash meme market</td>\n",
       "      <td>kill youll crash meme market</td>\n",
       "      <td>Catacomb82</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>2</td>\n",
       "      <td>If you were locked in a room with 49 other peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I bet he wrote that last message as he was sob...</td>\n",
       "      <td>bet wrote last message sobbing</td>\n",
       "      <td>bet wrote last messag sob</td>\n",
       "      <td>bet wrote last messag sob</td>\n",
       "      <td>Dorian-throwaway</td>\n",
       "      <td>niceguys</td>\n",
       "      <td>5</td>\n",
       "      <td>You're not even that pretty!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment  \\\n",
       "0      0  Actually most of her supporters and sane peopl...   \n",
       "1      0  They cant survive without an echo chamber whic...   \n",
       "2      0              youre pretty cute yourself 1729 total   \n",
       "3      0         If you kill me youll crash the meme market   \n",
       "4      0  I bet he wrote that last message as he was sob...   \n",
       "\n",
       "                                  comment_lc_stopped  \\\n",
       "0  actually supporters sane people saw media doin...   \n",
       "1    cant survive without echo chamber great america   \n",
       "2                       youre pretty cute 1729 total   \n",
       "3                       kill youll crash meme market   \n",
       "4                     bet wrote last message sobbing   \n",
       "\n",
       "                                     comment_stemmed  \\\n",
       "0  actual support sane peopl saw media doingespec...   \n",
       "1     cant surviv without echo chamber great america   \n",
       "2                        your pretti cute 1729 total   \n",
       "3                       kill youll crash meme market   \n",
       "4                          bet wrote last messag sob   \n",
       "\n",
       "                              comment_stemmed_lemmed                author  \\\n",
       "0  actual support sane peopl saw medium doingespe...           Quinnjester   \n",
       "1     cant surviv without echo chamber great america  TheGettysburgAddress   \n",
       "2                        your pretti cute 1729 total    Sempiternally_free   \n",
       "3                       kill youll crash meme market            Catacomb82   \n",
       "4                          bet wrote last messag sob      Dorian-throwaway   \n",
       "\n",
       "    subreddit  score                                     parent_comment  \n",
       "0    politics      3  Hillary's Surrogotes Told to Blame Media for '...  \n",
       "1  The_Donald     13  Thank God Liberals like to live in concentrate...  \n",
       "2   2007scape      8        Saw this cutie training his Attack today...  \n",
       "3   AskReddit      2  If you were locked in a room with 49 other peo...  \n",
       "4    niceguys      5                       You're not even that pretty!  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "\n",
    "data_test['comment_stemmed_lemmed'] = data_test['comment_stemmed'].apply(lemmatize_each_word)\n",
    "data_test = reorder_col_headers(data_test, \n",
    "                                 ['label', 'comment', 'comment_lc_stopped', 'comment_stemmed', 'comment_stemmed_lemmed',\n",
    "                                  'author', 'subreddit', 'score',  'parent_comment'])\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate CountVectorizer() from sklearn.feature_extraction.text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit and transform count_vectorizer on **data_train.comment_stemmed_lemmed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1010773, 165660)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts = count_vectorizer.fit_transform(data_train.comment_stemmed_lemmed)\n",
    "type(X_train_counts)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform count_vectorizer (do NOT fit) on **data_test.comment_stemmed_lemmed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251594, 165660)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_counts = count_vectorizer.transform(data_test.comment_stemmed_lemmed)\n",
    "X_test_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate TfidfTransformer() from sklearn.feature_extraction.text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit and transform tfidf_transformer on **X_train_counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1010773, 165660)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform tfidf_transformer (do NOT fit) on **X_test_counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251594, 165660)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "X_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit a Multinomial Naive Bayes linear model on (X_train_tfidf, data_train.label) to create a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifer = MultinomialNB().fit(X_train_tfidf, data_train.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the classifier to predict the labels in X_test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = classifer.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predict[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate classifier based on accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125341"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test_predict == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126253"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test_predict == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false positives\n",
    "\n",
    "predicted_actual = pd.DataFrame(y_test_predict, data_test.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "label  0  0  0  0  0  0  0  0  0  0  ...  0  0  0  0  0  0  0  0  0  0\n",
       "0      0  1  1  1  0  0  0  0  1  1  ...  0  0  0  0  0  1  1  1  1  0\n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_actual[0:30].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.mean(y_test_predict == data_test.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6646263424405987\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100    0\n",
       "101    0\n",
       "102    0\n",
       "103    0\n",
       "104    0\n",
       "105    0\n",
       "106    0\n",
       "107    0\n",
       "108    0\n",
       "109    0\n",
       "110    1\n",
       "111    0\n",
       "112    0\n",
       "113    1\n",
       "114    0\n",
       "115    0\n",
       "116    0\n",
       "117    0\n",
       "118    0\n",
       "119    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.label[100:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
